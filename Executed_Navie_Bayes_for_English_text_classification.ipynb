{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdXLmuHzwiSl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tMfPTE2wyA1"
      },
      "outputs": [],
      "source": [
        "  class NaiveBayes:\n",
        "    \n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "        self.vocab = set()\n",
        "        self.class_word_counts = defaultdict(lambda: defaultdict(int))\n",
        "        self.class_doc_counts = defaultdict(int)\n",
        "        self.num_docs = 0\n",
        "        \n",
        "    def preprocess(self, text):\n",
        "        # Remove punctuations and convert to lowercase\n",
        "        text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "        # Remove stop words\n",
        "        stop_words = set(['a', 'an', 'the', 'in', 'on', 'at', 'of', 'to', 'for', 'by', 'with', 'from', 'and'])\n",
        "        tokens = text.split()\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "        return tokens\n",
        "        \n",
        "    def train(self, documents):\n",
        "        for document, category in documents:\n",
        "            tokens = self.preprocess(document)\n",
        "            self.vocab.update(tokens)\n",
        "            self.class_doc_counts[category] += 1\n",
        "            self.num_docs += 1\n",
        "            for word in tokens:\n",
        "                self.class_word_counts[category][word] += 1\n",
        "        \n",
        "    def predict(self, document):\n",
        "        tokens = self.preprocess(document)\n",
        "        posteriors = {category: 0 for category in self.classes}\n",
        "        for category in self.classes:\n",
        "            prior = self.class_doc_counts[category] / self.num_docs\n",
        "            posterior = prior\n",
        "            for word in tokens:\n",
        "                word_count = self.class_word_counts[category][word]\n",
        "                total_count = sum(self.class_word_counts[category].values())\n",
        "                conditional = word_count / total_count\n",
        "                posterior *= conditional\n",
        "            posteriors[category] = posterior\n",
        "        return max(posteriors, key=posteriors.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDRX-1B9w1lk",
        "outputId": "b13c6bc4-0e85-4c74-e5d1-f1b734888564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The document \"ELECTION is coming up\" belongs to the category \"politics\"\n",
            "The document \"The sun is bright\" belongs to the category \"weather\"\n",
            "The document \"The economy is improving\" belongs to the category \"economy\"\n"
          ]
        }
      ],
      "source": [
        "docs = [\n",
        "    ('The sky is blue', 'weather'),\n",
        "    ('The sun is bright', 'weather'),\n",
        "    ('The news is depressing', 'politics'),\n",
        "    ('The economy is improving', 'economy'),\n",
        "    ('The movie was great', 'entertainment'),\n",
        "    ('I love pizza', 'food'),\n",
        "    ('The game was exciting', 'sports'),\n",
        "    ('The team played poorly', 'sports'),\n",
        "    ('The election is coming up', 'politics'),\n",
        "]\n",
        "\n",
        "nb = NaiveBayes(['weather', 'politics', 'economy', 'entertainment', 'food', 'sports'])\n",
        "nb.train(docs)\n",
        "\n",
        "# Predict the category of a new document\n",
        "new_doc1 = 'ELECTION is coming up'\n",
        "new_doc2 = 'The sun is bright'\n",
        "new_doc3 = 'The economy is improving'\n",
        "category1 = nb.predict(new_doc1)\n",
        "category2 = nb.predict(new_doc2)\n",
        "category3 = nb.predict(new_doc3)\n",
        "print(f'The document \"{new_doc1}\" belongs to the category \"{category1}\"')\n",
        "print(f'The document \"{new_doc2}\" belongs to the category \"{category2}\"')\n",
        "print(f'The document \"{new_doc3}\" belongs to the category \"{category3}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K11n6qrztmV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "72b2382ece9768098284d92bbc69d35954e75b60d1e25897d1389c232f4796f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
